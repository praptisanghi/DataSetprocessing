{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c729151-9037-4964-9b4a-3dfd2ba52927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Serial No   Value 1   Value 2\n",
      "0           1  41.29325  350.3584\n",
      "1           2  41.28514  350.3575\n",
      "2           3  41.29660  350.3566\n",
      "3           4  41.28280  350.3556\n",
      "4           5  41.29857  350.3547\n",
      "5           6  41.28386  350.3539\n",
      "6           7  41.29741  350.3530\n",
      "7           8  41.28809  350.3521\n",
      "8           9  41.29518  350.3511\n",
      "9          10  41.29211  350.3502\n",
      "10         11  41.29552  350.3493\n",
      "11         12  41.29306  350.3484\n",
      "12         13  41.29965  350.3475\n",
      "13         14  41.29167  350.3466\n",
      "14         15  41.30502  350.3457\n",
      "15         16  41.29145  350.3448\n",
      "16         17  41.30813  350.3438\n",
      "17         18  41.29485  350.3429\n",
      "18         19  41.30829  350.3421\n",
      "19         20  41.30056  350.3412\n",
      "    Serial No   Value 1   Value 2\n",
      "0           1  95.86071  371.6709\n",
      "1           2  95.35882  407.9387\n",
      "2           3  95.40144  382.5838\n",
      "3           4  95.70759  345.9366\n",
      "4           5  95.31560  357.8438\n",
      "5           6  88.58551  359.9370\n",
      "6           7  88.02782  388.5065\n",
      "7           8  88.46798  399.8832\n",
      "8           9  88.32325  368.3690\n",
      "9          10  88.14842  349.4844\n",
      "10         11  81.77011  361.0578\n",
      "11         12  81.44059  392.8607\n",
      "12         13  81.58759  405.2255\n",
      "13         14  81.71937  371.5980\n",
      "14         15  81.44735  354.4435\n",
      "15         16  75.33122  362.3086\n",
      "16         17  75.14486  397.2167\n",
      "17         18  75.11451  409.4827\n",
      "18         19  75.32193  373.2194\n",
      "19         20  75.11446  358.4485\n",
      "Serial No    0\n",
      "Value 1      0\n",
      "Value 2      0\n",
      "dtype: int64\n",
      "Serial No    0\n",
      "Value 1      0\n",
      "Value 2      0\n",
      "dtype: int64\n",
      "       Serial No    Value 1     Value 2\n",
      "count   20.00000  20.000000   20.000000\n",
      "mean    10.50000  41.295061  350.349770\n",
      "std      5.91608   0.007182    0.005369\n",
      "min      1.00000  41.282800  350.341200\n",
      "25%      5.75000  41.291615  350.345475\n",
      "50%     10.50000  41.295015  350.349750\n",
      "75%     15.25000  41.298840  350.354100\n",
      "max     20.00000  41.308290  350.358400\n",
      "       Serial No    Value 1     Value 2\n",
      "count   20.00000  20.000000   20.000000\n",
      "mean    10.50000  85.159457  375.900765\n",
      "std      5.91608   7.769250   20.496212\n",
      "min      1.00000  75.114460  345.936600\n",
      "25%      5.75000  79.913247  359.564875\n",
      "50%     10.50000  84.898965  371.634450\n",
      "75%     15.25000  90.268033  393.949700\n",
      "max     20.00000  95.860710  409.482700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('NoFault.xlsx')\n",
    "df2 = pd.read_excel('Fault.xlsx')\n",
    "\n",
    "print(df1.head(20))\n",
    "print(df2.head(20))\n",
    "\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecb21d8-272a-4530-875d-a89c6ddca30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Serial No   Value 1   Value 2\n",
      "0           1  41.29325  350.3584\n",
      "1           2  41.28514  350.3575\n",
      "2           3  41.29660  350.3566\n",
      "3           4  41.28280  350.3556\n",
      "4           5  41.29857  350.3547\n",
      "5           6  41.28386  350.3539\n",
      "6           7  41.29741  350.3530\n",
      "7           8  41.28809  350.3521\n",
      "8           9  41.29518  350.3511\n",
      "9          10  41.29211  350.3502\n",
      "10         11  41.29552  350.3493\n",
      "11         12  41.29306  350.3484\n",
      "12         13  41.29965  350.3475\n",
      "13         14  41.29167  350.3466\n",
      "14         15  41.30502  350.3457\n",
      "15         16  41.29145  350.3448\n",
      "16         17  41.30813  350.3438\n",
      "17         18  41.29485  350.3429\n",
      "18         19  41.30829  350.3421\n",
      "19         20  41.30056  350.3412\n",
      "    Serial No   Value 1   Value 2\n",
      "0           1  95.86071  371.6709\n",
      "1           2  95.35882  407.9387\n",
      "2           3  95.40144  382.5838\n",
      "3           4  95.70759  345.9366\n",
      "4           5  95.31560  357.8438\n",
      "5           6  88.58551  359.9370\n",
      "6           7  88.02782  388.5065\n",
      "7           8  88.46798  399.8832\n",
      "8           9  88.32325  368.3690\n",
      "9          10  88.14842  349.4844\n",
      "10         11  81.77011  361.0578\n",
      "11         12  81.44059  392.8607\n",
      "12         13  81.58759  405.2255\n",
      "13         14  81.71937  371.5980\n",
      "14         15  81.44735  354.4435\n",
      "15         16  75.33122  362.3086\n",
      "16         17  75.14486  397.2167\n",
      "17         18  75.11451  409.4827\n",
      "18         19  75.32193  373.2194\n",
      "19         20  75.11446  358.4485\n",
      "Serial No    0\n",
      "Value 1      0\n",
      "Value 2      0\n",
      "dtype: int64\n",
      "Serial No    0\n",
      "Value 1      0\n",
      "Value 2      0\n",
      "dtype: int64\n",
      "       Serial No    Value 1     Value 2\n",
      "count   20.00000  20.000000   20.000000\n",
      "mean    10.50000  41.295061  350.349770\n",
      "std      5.91608   0.007182    0.005369\n",
      "min      1.00000  41.282800  350.341200\n",
      "25%      5.75000  41.291615  350.345475\n",
      "50%     10.50000  41.295015  350.349750\n",
      "75%     15.25000  41.298840  350.354100\n",
      "max     20.00000  41.308290  350.358400\n",
      "       Serial No    Value 1     Value 2\n",
      "count   20.00000  20.000000   20.000000\n",
      "mean    10.50000  85.159457  375.900765\n",
      "std      5.91608   7.769250   20.496212\n",
      "min      1.00000  75.114460  345.936600\n",
      "25%      5.75000  79.913247  359.564875\n",
      "50%     10.50000  84.898965  371.634450\n",
      "75%     15.25000  90.268033  393.949700\n",
      "max     20.00000  95.860710  409.482700\n",
      "    Serial No   Value 1   Value 2\n",
      "0           1  41.29325  350.3584\n",
      "1           2  41.28514  350.3575\n",
      "2           3  41.29660  350.3566\n",
      "3           4  41.28280  350.3556\n",
      "4           5  41.29857  350.3547\n",
      "5           6  41.28386  350.3539\n",
      "6           7  41.29741  350.3530\n",
      "7           8  41.28809  350.3521\n",
      "8           9  41.29518  350.3511\n",
      "9          10  41.29211  350.3502\n",
      "10         11  41.29552  350.3493\n",
      "11         12  41.29306  350.3484\n",
      "12         13  41.29965  350.3475\n",
      "13         14  41.29167  350.3466\n",
      "14         15  41.30502  350.3457\n",
      "15         16  41.29145  350.3448\n",
      "16         17  41.30813  350.3438\n",
      "17         18  41.29485  350.3429\n",
      "18         19  41.30829  350.3421\n",
      "19         20  41.30056  350.3412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('NoFault.xlsx')\n",
    "df2 = pd.read_excel('Fault.xlsx')\n",
    "\n",
    "print(df1.head(20))\n",
    "print(df2.head(20))\n",
    "\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e0b476-4f78-442c-870a-9809a055e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_6028\\3510571820.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(X.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "fault_data = pd.read_excel('Fault.xlsx')\n",
    "nofault_data = pd.read_excel('NoFault.xlsx')\n",
    "\n",
    "# Add a label column to each dataset\n",
    "fault_data['label'] = 1\n",
    "nofault_data['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([fault_data, nofault_data], ignore_index=True)\n",
    "\n",
    "# Rename columns to standard names for easier access\n",
    "data.columns = ['Serial no', 'Value 1', 'Value 2', 'label']\n",
    "\n",
    "# Select the features and labels\n",
    "X = data[['Value 1', 'Value 2']]  # Features\n",
    "y = data['label']  # Labels\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b354a0-2961-49fd-b798-164a1a1b3b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_6028\\2245230521.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(X.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 0]\n",
      " [0 7]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "fault_data = pd.read_excel('Fault.xlsx')\n",
    "nofault_data = pd.read_excel('NoFault.xlsx')\n",
    "\n",
    "# Add a label column to each dataset\n",
    "fault_data['label'] = 1\n",
    "nofault_data['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([fault_data, nofault_data], ignore_index=True)\n",
    "\n",
    "# Rename columns to standard names for easier access\n",
    "data.columns = ['Serial no', 'Value 1', 'Value 2', 'label']\n",
    "\n",
    "# Select the features and labels\n",
    "X = data[['Value 1', 'Value 2']]  # Features\n",
    "y = data['label']  # Labels\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Additional metrics can be added for more insights\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eea11f6-031a-4b9b-aa7a-32155a952ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 0]\n",
      " [0 7]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "fault_data = pd.read_excel('Fault.xlsx')\n",
    "nofault_data = pd.read_excel('NoFault.xlsx')\n",
    "\n",
    "# Add a label column to each dataset\n",
    "fault_data['label'] = 1\n",
    "nofault_data['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([fault_data, nofault_data], ignore_index=True)\n",
    "\n",
    "# Rename columns to standard names for easier access\n",
    "data.columns = ['Serial no', 'Value 1', 'Value 2', 'label']\n",
    "\n",
    "# Select the features and labels\n",
    "X = data[['Value 1', 'Value 2']]  # Features\n",
    "y = data['label']  # Labels\n",
    "\n",
    "# Handle missing values using .loc to avoid the warning\n",
    "X.loc[:, 'Value 1'] = X['Value 1'].fillna(X['Value 1'].mean())\n",
    "X.loc[:, 'Value 2'] = X['Value 2'].fillna(X['Value 2'].mean())\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    " \n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Additional metrics can be added for more insights\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c630d9-273a-4a00-96a5-658e5a984e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
